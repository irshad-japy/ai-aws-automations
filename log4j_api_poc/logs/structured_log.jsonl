{"@timestamp": "2025-05-01T18:08:22.293+0530", "@message": "Running Spark version 3.3.2", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.448+0530", "@message": "==============================================================", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceUtils", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.448+0530", "@message": "No custom resources configured for spark.driver.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceUtils", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.451+0530", "@message": "==============================================================", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceUtils", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.451+0530", "@message": "Submitted application: Log4jLoggingExample", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.465+0530", "@message": "Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceProfile", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.475+0530", "@message": "Limiting resource is cpu", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceProfile", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.477+0530", "@message": "Added ResourceProfile id: 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceProfileManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.514+0530", "@message": "Changing view acls to: erirs", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.526+0530", "@message": "Changing modify acls to: erirs", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.527+0530", "@message": "Changing view acls groups to: ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.527+0530", "@message": "Changing modify acls groups to: ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.529+0530", "@message": "SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(erirs); groups with view permissions: Set(); users  with modify permissions: Set(erirs); groups with modify permissions: Set()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.855+0530", "@message": "Successfully started service 'sparkDriver' on port 61512.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.874+0530", "@message": "Registering MapOutputTracker", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.912+0530", "@message": "Registering BlockManagerMaster", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.935+0530", "@message": "Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMasterEndpoint", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.938+0530", "@message": "BlockManagerMasterEndpoint up", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMasterEndpoint", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.943+0530", "@message": "Registering BlockManagerMasterHeartbeat", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.963+0530", "@message": "Created local directory at C:\Users\erirs\AppData\Local\Temp\blockmgr-a252ff32-726e-4876-a82d-625f9f793713", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.DiskBlockManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.982+0530", "@message": "MemoryStore started with capacity 434.4 MiB", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:22.996+0530", "@message": "Registering OutputCommitCoordinator", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.038+0530", "@message": "Logging initialized @2659ms to org.sparkproject.jetty.util.log.Slf4jLog", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.util.log", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.108+0530", "@message": "jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.15+6-LTS", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.Server", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.130+0530", "@message": "Started @2753ms", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.Server", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.171+0530", "@message": "Started ServerConnector@292456fb{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.AbstractConnector", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.171+0530", "@message": "Successfully started service 'SparkUI' on port 4040.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.192+0530", "@message": "Started o.s.j.s.ServletContextHandler@7cd6bc3d{/,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.300+0530", "@message": "Starting executor ID driver on host IrshadAlam", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.310+0530", "@message": "Starting executor with user classpath (userClassPathFirst = false): ''", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.337+0530", "@message": "Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61514.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.337+0530", "@message": "Server created on IrshadAlam:61514", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.network.netty.NettyBlockTransferService", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.340+0530", "@message": "Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.345+0530", "@message": "Registering BlockManager BlockManagerId(driver, IrshadAlam, 61514, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMaster", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.349+0530", "@message": "Registering block manager IrshadAlam:61514 with 434.4 MiB RAM, BlockManagerId(driver, IrshadAlam, 61514, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMasterEndpoint", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:08:23.352+0530", "@message": "Registered BlockManager BlockManagerId(driver, IrshadAlam, 61514, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMaster", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.353+0530", "@message": "Initialized BlockManager: BlockManagerId(driver, IrshadAlam, 61514, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.459+0530", "@message": "Stopped o.s.j.s.ServletContextHandler@7cd6bc3d{/,null,STOPPED,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.461+0530", "@message": "Started o.s.j.s.ServletContextHandler@34a14efa{/jobs,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.462+0530", "@message": "Started o.s.j.s.ServletContextHandler@50bcdb9f{/jobs/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.462+0530", "@message": "Started o.s.j.s.ServletContextHandler@fb56f1b{/jobs/job,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.465+0530", "@message": "Started o.s.j.s.ServletContextHandler@73df9053{/jobs/job/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.467+0530", "@message": "Started o.s.j.s.ServletContextHandler@77a92214{/stages,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.468+0530", "@message": "Started o.s.j.s.ServletContextHandler@31c99e55{/stages/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.470+0530", "@message": "Started o.s.j.s.ServletContextHandler@442e95bf{/stages/stage,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.472+0530", "@message": "Started o.s.j.s.ServletContextHandler@9f0d774{/stages/stage/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.473+0530", "@message": "Started o.s.j.s.ServletContextHandler@3712091a{/stages/pool,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.475+0530", "@message": "Started o.s.j.s.ServletContextHandler@2add88e4{/stages/pool/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.479+0530", "@message": "Started o.s.j.s.ServletContextHandler@530159e{/storage,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.480+0530", "@message": "Started o.s.j.s.ServletContextHandler@2b1fb198{/storage/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.480+0530", "@message": "Started o.s.j.s.ServletContextHandler@60952e97{/storage/rdd,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.483+0530", "@message": "Started o.s.j.s.ServletContextHandler@47911cd4{/storage/rdd/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.484+0530", "@message": "Started o.s.j.s.ServletContextHandler@9e80e41{/environment,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.484+0530", "@message": "Started o.s.j.s.ServletContextHandler@705223ba{/environment/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.485+0530", "@message": "Started o.s.j.s.ServletContextHandler@7a88cce5{/executors,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.487+0530", "@message": "Started o.s.j.s.ServletContextHandler@735d790b{/executors/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.488+0530", "@message": "Started o.s.j.s.ServletContextHandler@268a9c7d{/executors/threadDump,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.489+0530", "@message": "Started o.s.j.s.ServletContextHandler@32c05574{/executors/threadDump/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.495+0530", "@message": "Started o.s.j.s.ServletContextHandler@16f58623{/static,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.495+0530", "@message": "Started o.s.j.s.ServletContextHandler@4910c70a{/,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.498+0530", "@message": "Started o.s.j.s.ServletContextHandler@27ec1695{/api,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.499+0530", "@message": "Started o.s.j.s.ServletContextHandler@7a0e04ec{/jobs/job/kill,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.500+0530", "@message": "Started o.s.j.s.ServletContextHandler@a7f3dd8{/stages/stage/kill,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.504+0530", "@message": "Started o.s.j.s.ServletContextHandler@48d214bc{/metrics/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.639+0530", "@message": "? This is an INFO message from Log4j logger.", "@fields": {"priority": "INFO", "logger_name": "my.custom.logger", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.639+0530", "@message": "?? This is a WARNING message from Log4j logger.", "@fields": {"priority": "WARN", "logger_name": "my.custom.logger", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.639+0530", "@message": "? This is an ERROR message from Log4j logger.", "@fields": {"priority": "ERROR", "logger_name": "my.custom.logger", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.907+0530", "@message": "Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.sql.internal.SharedState", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.917+0530", "@message": "Warehouse path is 'file:/C:/Users/erirs/projects/ird-projects/aws_projects/log4j_api_poc/spark-warehouse'.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.sql.internal.SharedState", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.917+0530", "@message": "Started o.s.j.s.ServletContextHandler@4f62b14b{/SQL,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.917+0530", "@message": "Started o.s.j.s.ServletContextHandler@1f3c5715{/SQL/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.926+0530", "@message": "Started o.s.j.s.ServletContextHandler@70677ef3{/SQL/execution,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.928+0530", "@message": "Started o.s.j.s.ServletContextHandler@25a36f4d{/SQL/execution/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:23.935+0530", "@message": "Started o.s.j.s.ServletContextHandler@734966a1{/static/sql,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:26.089+0530", "@message": "Code generated in 66.724 ms", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:26.131+0530", "@message": "Starting job: showString at NativeMethodAccessorImpl.java:0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:26.151+0530", "@message": "Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.152+0530", "@message": "Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.153+0530", "@message": "Parents of final stage: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.156+0530", "@message": "Missing parents: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.159+0530", "@message": "Submitting ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.244+0530", "@message": "Block broadcast_0 stored as values in memory (estimated size 12.3 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.337+0530", "@message": "Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.349+0530", "@message": "Added broadcast_0_piece0 in memory on IrshadAlam:61514 (size: 6.5 KiB, free: 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerInfo", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:08:26.353+0530", "@message": "Created broadcast 0 from broadcast at DAGScheduler.scala:1513", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.364+0530", "@message": "Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.367+0530", "@message": "Adding task set 0.0 with 1 tasks resource profile 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.405+0530", "@message": "Starting task 0.0 in stage 0.0 (TID 0) (IrshadAlam, executor driver, partition 0, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:26.422+0530", "@message": "Running task 0.0 in stage 0.0 (TID 0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 0.0 (TID 0)"}}
{"@timestamp": "2025-05-01T18:08:26.910+0530", "@message": "Times: total = 427, boot = 407, init = 20, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 0.0 in stage 0.0 (TID 0)"}}
{"@timestamp": "2025-05-01T18:08:26.930+0530", "@message": "Finished task 0.0 in stage 0.0 (TID 0). 1789 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 0.0 (TID 0)"}}
{"@timestamp": "2025-05-01T18:08:26.938+0530", "@message": "Finished task 0.0 in stage 0.0 (TID 0) in 541 ms on IrshadAlam (executor driver) (1/1)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:08:26.944+0530", "@message": "Removed TaskSet 0.0, whose tasks have all completed, from pool ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:08:26.947+0530", "@message": "Connected to AccumulatorServer at host: 127.0.0.1 port: 61515", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonAccumulatorV2", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.949+0530", "@message": "ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 0.780 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.952+0530", "@message": "Job 0 is finished. Cancelling potential speculative or zombie tasks for this job", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.953+0530", "@message": "Killing all running tasks in stage 0: Stage finished", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.957+0530", "@message": "Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 0.824699 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:26.966+0530", "@message": "Starting job: showString at NativeMethodAccessorImpl.java:0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:26.970+0530", "@message": "Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.971+0530", "@message": "Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.971+0530", "@message": "Parents of final stage: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.972+0530", "@message": "Missing parents: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.972+0530", "@message": "Submitting ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.976+0530", "@message": "Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.978+0530", "@message": "Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.980+0530", "@message": "Added broadcast_1_piece0 in memory on IrshadAlam:61514 (size: 6.5 KiB, free: 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerInfo", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:08:26.981+0530", "@message": "Created broadcast 1 from broadcast at DAGScheduler.scala:1513", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.982+0530", "@message": "Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1, 2, 3, 4))", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.983+0530", "@message": "Adding task set 1.0 with 4 tasks resource profile 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:26.984+0530", "@message": "Starting task 0.0 in stage 1.0 (TID 1) (IrshadAlam, executor driver, partition 1, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-4"}}
{"@timestamp": "2025-05-01T18:08:26.984+0530", "@message": "Starting task 1.0 in stage 1.0 (TID 2) (IrshadAlam, executor driver, partition 2, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-4"}}
{"@timestamp": "2025-05-01T18:08:26.986+0530", "@message": "Starting task 2.0 in stage 1.0 (TID 3) (IrshadAlam, executor driver, partition 3, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-4"}}
{"@timestamp": "2025-05-01T18:08:26.987+0530", "@message": "Starting task 3.0 in stage 1.0 (TID 4) (IrshadAlam, executor driver, partition 4, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-4"}}
{"@timestamp": "2025-05-01T18:08:26.987+0530", "@message": "Running task 0.0 in stage 1.0 (TID 1)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 1.0 (TID 1)"}}
{"@timestamp": "2025-05-01T18:08:26.987+0530", "@message": "Running task 1.0 in stage 1.0 (TID 2)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 1.0 in stage 1.0 (TID 2)"}}
{"@timestamp": "2025-05-01T18:08:26.987+0530", "@message": "Running task 3.0 in stage 1.0 (TID 4)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 3.0 in stage 1.0 (TID 4)"}}
{"@timestamp": "2025-05-01T18:08:26.987+0530", "@message": "Running task 2.0 in stage 1.0 (TID 3)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 2.0 in stage 1.0 (TID 3)"}}
{"@timestamp": "2025-05-01T18:08:27.405+0530", "@message": "Times: total = 399, boot = 386, init = 13, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 1.0 in stage 1.0 (TID 2)"}}
{"@timestamp": "2025-05-01T18:08:27.784+0530", "@message": "Times: total = 764, boot = 753, init = 11, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 0.0 in stage 1.0 (TID 1)"}}
{"@timestamp": "2025-05-01T18:08:28.168+0530", "@message": "Times: total = 1151, boot = 1132, init = 19, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 2.0 in stage 1.0 (TID 3)"}}
{"@timestamp": "2025-05-01T18:08:28.526+0530", "@message": "Finished task 1.0 in stage 1.0 (TID 2). 1746 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 1.0 in stage 1.0 (TID 2)"}}
{"@timestamp": "2025-05-01T18:08:28.522+0530", "@message": "Finished task 2.0 in stage 1.0 (TID 3). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 2.0 in stage 1.0 (TID 3)"}}
{"@timestamp": "2025-05-01T18:08:28.526+0530", "@message": "Finished task 0.0 in stage 1.0 (TID 1). 1746 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 1.0 (TID 1)"}}
{"@timestamp": "2025-05-01T18:08:28.530+0530", "@message": "Finished task 2.0 in stage 1.0 (TID 3) in 1544 ms on IrshadAlam (executor driver) (1/4)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:08:28.530+0530", "@message": "Finished task 0.0 in stage 1.0 (TID 1) in 1546 ms on IrshadAlam (executor driver) (2/4)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-3"}}
{"@timestamp": "2025-05-01T18:08:28.533+0530", "@message": "Finished task 1.0 in stage 1.0 (TID 2) in 1549 ms on IrshadAlam (executor driver) (3/4)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:08:28.544+0530", "@message": "Times: total = 1543, boot = 1524, init = 19, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 3.0 in stage 1.0 (TID 4)"}}
{"@timestamp": "2025-05-01T18:08:28.544+0530", "@message": "Finished task 3.0 in stage 1.0 (TID 4). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 3.0 in stage 1.0 (TID 4)"}}
{"@timestamp": "2025-05-01T18:08:28.553+0530", "@message": "Finished task 3.0 in stage 1.0 (TID 4) in 1566 ms on IrshadAlam (executor driver) (4/4)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:08:28.553+0530", "@message": "Removed TaskSet 1.0, whose tasks have all completed, from pool ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:08:28.553+0530", "@message": "ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.579 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.557+0530", "@message": "Job 1 is finished. Cancelling potential speculative or zombie tasks for this job", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.558+0530", "@message": "Killing all running tasks in stage 1: Stage finished", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.559+0530", "@message": "Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 1.589450 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:28.562+0530", "@message": "Starting job: showString at NativeMethodAccessorImpl.java:0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:28.562+0530", "@message": "Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 7 output partitions", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.566+0530", "@message": "Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.566+0530", "@message": "Parents of final stage: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.567+0530", "@message": "Missing parents: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.567+0530", "@message": "Submitting ResultStage 2 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.573+0530", "@message": "Block broadcast_2 stored as values in memory (estimated size 12.3 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.581+0530", "@message": "Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.3 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.584+0530", "@message": "Added broadcast_2_piece0 in memory on IrshadAlam:61514 (size: 6.5 KiB, free: 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerInfo", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:08:28.585+0530", "@message": "Created broadcast 2 from broadcast at DAGScheduler.scala:1513", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.586+0530", "@message": "Submitting 7 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11))", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.586+0530", "@message": "Adding task set 2.0 with 7 tasks resource profile 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:28.586+0530", "@message": "Starting task 0.0 in stage 2.0 (TID 5) (IrshadAlam, executor driver, partition 5, PROCESS_LOCAL, 4466 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.586+0530", "@message": "Starting task 1.0 in stage 2.0 (TID 6) (IrshadAlam, executor driver, partition 6, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.592+0530", "@message": "Starting task 2.0 in stage 2.0 (TID 7) (IrshadAlam, executor driver, partition 7, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.593+0530", "@message": "Starting task 3.0 in stage 2.0 (TID 8) (IrshadAlam, executor driver, partition 8, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.593+0530", "@message": "Starting task 4.0 in stage 2.0 (TID 9) (IrshadAlam, executor driver, partition 9, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.594+0530", "@message": "Starting task 5.0 in stage 2.0 (TID 10) (IrshadAlam, executor driver, partition 10, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.594+0530", "@message": "Starting task 6.0 in stage 2.0 (TID 11) (IrshadAlam, executor driver, partition 11, PROCESS_LOCAL, 4466 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-9"}}
{"@timestamp": "2025-05-01T18:08:28.595+0530", "@message": "Running task 3.0 in stage 2.0 (TID 8)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 3.0 in stage 2.0 (TID 8)"}}
{"@timestamp": "2025-05-01T18:08:28.595+0530", "@message": "Running task 1.0 in stage 2.0 (TID 6)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 1.0 in stage 2.0 (TID 6)"}}
{"@timestamp": "2025-05-01T18:08:28.595+0530", "@message": "Running task 2.0 in stage 2.0 (TID 7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 2.0 in stage 2.0 (TID 7)"}}
{"@timestamp": "2025-05-01T18:08:28.595+0530", "@message": "Running task 0.0 in stage 2.0 (TID 5)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 2.0 (TID 5)"}}
{"@timestamp": "2025-05-01T18:08:28.596+0530", "@message": "Running task 4.0 in stage 2.0 (TID 9)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 4.0 in stage 2.0 (TID 9)"}}
{"@timestamp": "2025-05-01T18:08:28.596+0530", "@message": "Running task 5.0 in stage 2.0 (TID 10)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 5.0 in stage 2.0 (TID 10)"}}
{"@timestamp": "2025-05-01T18:08:28.596+0530", "@message": "Running task 6.0 in stage 2.0 (TID 11)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 6.0 in stage 2.0 (TID 11)"}}
{"@timestamp": "2025-05-01T18:08:28.616+0530", "@message": "Removed broadcast_1_piece0 on IrshadAlam:61514 in memory (size: 6.5 KiB, free: 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerInfo", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:08:28.622+0530", "@message": "Removed broadcast_0_piece0 on IrshadAlam:61514 in memory (size: 6.5 KiB, free: 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerInfo", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:08:29.039+0530", "@message": "Times: total = 426, boot = 412, init = 14, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 0.0 in stage 2.0 (TID 5)"}}
{"@timestamp": "2025-05-01T18:08:29.422+0530", "@message": "Times: total = 806, boot = 794, init = 12, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 5.0 in stage 2.0 (TID 10)"}}
{"@timestamp": "2025-05-01T18:08:29.802+0530", "@message": "Times: total = 1187, boot = 1174, init = 13, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 6.0 in stage 2.0 (TID 11)"}}
{"@timestamp": "2025-05-01T18:08:30.176+0530", "@message": "Times: total = 1560, boot = 1551, init = 9, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 2.0 in stage 2.0 (TID 7)"}}
{"@timestamp": "2025-05-01T18:08:30.563+0530", "@message": "Times: total = 1953, boot = 1940, init = 13, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 4.0 in stage 2.0 (TID 9)"}}
{"@timestamp": "2025-05-01T18:08:30.963+0530", "@message": "Times: total = 2351, boot = 2339, init = 12, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 3.0 in stage 2.0 (TID 8)"}}
{"@timestamp": "2025-05-01T18:08:31.321+0530", "@message": "Finished task 3.0 in stage 2.0 (TID 8). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 3.0 in stage 2.0 (TID 8)"}}
{"@timestamp": "2025-05-01T18:08:31.322+0530", "@message": "Finished task 4.0 in stage 2.0 (TID 9). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 4.0 in stage 2.0 (TID 9)"}}
{"@timestamp": "2025-05-01T18:08:31.322+0530", "@message": "Finished task 6.0 in stage 2.0 (TID 11). 1782 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 6.0 in stage 2.0 (TID 11)"}}
{"@timestamp": "2025-05-01T18:08:31.322+0530", "@message": "Finished task 0.0 in stage 2.0 (TID 5). 1739 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 2.0 (TID 5)"}}
{"@timestamp": "2025-05-01T18:08:31.322+0530", "@message": "Finished task 2.0 in stage 2.0 (TID 7). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 2.0 in stage 2.0 (TID 7)"}}
{"@timestamp": "2025-05-01T18:08:31.322+0530", "@message": "Finished task 5.0 in stage 2.0 (TID 10). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 5.0 in stage 2.0 (TID 10)"}}
{"@timestamp": "2025-05-01T18:08:31.323+0530", "@message": "Finished task 6.0 in stage 2.0 (TID 11) in 2729 ms on IrshadAlam (executor driver) (1/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:08:31.324+0530", "@message": "Finished task 4.0 in stage 2.0 (TID 9) in 2731 ms on IrshadAlam (executor driver) (2/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-3"}}
{"@timestamp": "2025-05-01T18:08:31.324+0530", "@message": "Finished task 3.0 in stage 2.0 (TID 8) in 2732 ms on IrshadAlam (executor driver) (3/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:08:31.325+0530", "@message": "Finished task 2.0 in stage 2.0 (TID 7) in 2739 ms on IrshadAlam (executor driver) (4/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:08:31.327+0530", "@message": "Finished task 0.0 in stage 2.0 (TID 5) in 2741 ms on IrshadAlam (executor driver) (5/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:08:31.328+0530", "@message": "Finished task 5.0 in stage 2.0 (TID 10) in 2734 ms on IrshadAlam (executor driver) (6/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-3"}}
{"@timestamp": "2025-05-01T18:08:31.344+0530", "@message": "Times: total = 2733, boot = 2710, init = 23, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 1.0 in stage 2.0 (TID 6)"}}
{"@timestamp": "2025-05-01T18:08:31.345+0530", "@message": "Finished task 1.0 in stage 2.0 (TID 6). 1703 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 1.0 in stage 2.0 (TID 6)"}}
{"@timestamp": "2025-05-01T18:08:31.345+0530", "@message": "Finished task 1.0 in stage 2.0 (TID 6) in 2759 ms on IrshadAlam (executor driver) (7/7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:08:31.349+0530", "@message": "Removed TaskSet 2.0, whose tasks have all completed, from pool ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:08:31.350+0530", "@message": "ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 2.781 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:31.351+0530", "@message": "Job 2 is finished. Cancelling potential speculative or zombie tasks for this job", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:31.352+0530", "@message": "Killing all running tasks in stage 2: Stage finished", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:08:31.352+0530", "@message": "Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 2.788248 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.379+0530", "@message": "Code generated in 15.9669 ms", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.404+0530", "@message": "Stopped Spark@292456fb{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.AbstractConnector", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.411+0530", "@message": "Stopped Spark web UI at http://IrshadAlam:4040", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.ui.SparkUI", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.419+0530", "@message": "MapOutputTrackerMasterEndpoint stopped!", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.MapOutputTrackerMasterEndpoint", "thread": "dispatcher-event-loop-5"}}
{"@timestamp": "2025-05-01T18:08:31.435+0530", "@message": "MemoryStore cleared", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.436+0530", "@message": "BlockManager stopped", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManager", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.439+0530", "@message": "BlockManagerMaster stopped", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMaster", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:31.442+0530", "@message": "OutputCommitCoordinator stopped!", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint", "thread": "dispatcher-event-loop-6"}}
{"@timestamp": "2025-05-01T18:08:31.446+0530", "@message": "Successfully stopped SparkContext", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-3"}}
{"@timestamp": "2025-05-01T18:08:32.426+0530", "@message": "Shutdown hook called", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:08:32.426+0530", "@message": "Deleting directory C:\Users\erirs\AppData\Local\Temp\spark-0da486ec-cfb8-4437-8e22-034d7f09e0ef", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:08:32.426+0530", "@message": "Deleting directory C:\Users\erirs\AppData\Local\Temp\spark-9b033759-f8fd-4e58-bca1-553939c4ebef", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:08:32.426+0530", "@message": "Deleting directory C:\Users\erirs\AppData\Local\Temp\spark-9b033759-f8fd-4e58-bca1-553939c4ebef\pyspark-d2d41a60-04b6-4705-87a5-9c3a756c9f4a", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
