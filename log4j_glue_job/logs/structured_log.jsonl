{"@timestamp": "2025-05-01T18:19:49.782+0530", "@message": "Running Spark version 3.3.2", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.804+0530", "@message": "==============================================================", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceUtils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.804+0530", "@message": "No custom resources configured for spark.driver.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceUtils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.804+0530", "@message": "==============================================================", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceUtils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.809+0530", "@message": "Submitted application: GlueLoggerDemo", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.826+0530", "@message": "Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceProfile", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.832+0530", "@message": "Limiting resource is cpu", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceProfile", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.834+0530", "@message": "Added ResourceProfile id: 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.resource.ResourceProfileManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.876+0530", "@message": "Changing view acls to: erirs", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.876+0530", "@message": "Changing modify acls to: erirs", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.876+0530", "@message": "Changing view acls groups to: ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.876+0530", "@message": "Changing modify acls groups to: ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:49.876+0530", "@message": "SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(erirs); groups with view permissions: Set(); users  with modify permissions: Set(erirs); groups with modify permissions: Set()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SecurityManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.205+0530", "@message": "Successfully started service 'sparkDriver' on port 61719.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.238+0530", "@message": "Registering MapOutputTracker", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.284+0530", "@message": "Registering BlockManagerMaster", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.303+0530", "@message": "Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMasterEndpoint", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.304+0530", "@message": "BlockManagerMasterEndpoint up", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMasterEndpoint", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.306+0530", "@message": "Registering BlockManagerMasterHeartbeat", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.322+0530", "@message": "Created local directory at C:\Users\erirs\AppData\Local\Temp\blockmgr-37385845-daa9-40c2-8542-aa378c866b33", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.DiskBlockManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.343+0530", "@message": "MemoryStore started with capacity 434.4 MiB", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.368+0530", "@message": "Registering OutputCommitCoordinator", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkEnv", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.410+0530", "@message": "Logging initialized @2679ms to org.sparkproject.jetty.util.log.Slf4jLog", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.util.log", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.477+0530", "@message": "jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 17.0.15+6-LTS", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.Server", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.497+0530", "@message": "Started @2763ms", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.Server", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.555+0530", "@message": "Started ServerConnector@1ea5ff72{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.AbstractConnector", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.555+0530", "@message": "Successfully started service 'SparkUI' on port 4040.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.584+0530", "@message": "Started o.s.j.s.ServletContextHandler@f66d011{/,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.595+0530", "@message": "Added file file:///C:/Users/erirs/projects/ird-projects/aws_projects/my_glue_job/log4j.zip at file:///C:/Users/erirs/projects/ird-projects/aws_projects/my_glue_job/log4j.zip with timestamp 1746103789776", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.599+0530", "@message": "Copying C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\log4j.zip to C:\Users\erirs\AppData\Local\Temp\spark-dff97f00-ba7e-46cc-b039-eca868e29aac\userFiles-2828ee8d-4223-491b-8645-6ec3082d567c\log4j.zip", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.745+0530", "@message": "Starting executor ID driver on host IrshadAlam", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.757+0530", "@message": "Starting executor with user classpath (userClassPathFirst = false): ''", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.768+0530", "@message": "Fetching file:///C:/Users/erirs/projects/ird-projects/aws_projects/my_glue_job/log4j.zip with timestamp 1746103789776", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.778+0530", "@message": "C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\log4j.zip has been previously copied to C:\Users\erirs\AppData\Local\Temp\spark-dff97f00-ba7e-46cc-b039-eca868e29aac\userFiles-2828ee8d-4223-491b-8645-6ec3082d567c\log4j.zip", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.883+0530", "@message": "Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61721.", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.Utils", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.883+0530", "@message": "Server created on IrshadAlam:61721", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.network.netty.NettyBlockTransferService", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.885+0530", "@message": "Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.890+0530", "@message": "Registering BlockManager BlockManagerId(driver, IrshadAlam, 61721, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMaster", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.893+0530", "@message": "Registering block manager IrshadAlam:61721 with 434.4 MiB RAM, BlockManagerId(driver, IrshadAlam, 61721, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMasterEndpoint", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:19:50.895+0530", "@message": "Registered BlockManager BlockManagerId(driver, IrshadAlam, 61721, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMaster", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.896+0530", "@message": "Initialized BlockManager: BlockManagerId(driver, IrshadAlam, 61721, None)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManager", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.996+0530", "@message": "Stopped o.s.j.s.ServletContextHandler@f66d011{/,null,STOPPED,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.997+0530", "@message": "Started o.s.j.s.ServletContextHandler@7e0409a4{/jobs,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.998+0530", "@message": "Started o.s.j.s.ServletContextHandler@7de3aad1{/jobs/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:50.999+0530", "@message": "Started o.s.j.s.ServletContextHandler@3143b5fa{/jobs/job,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.000+0530", "@message": "Started o.s.j.s.ServletContextHandler@54ff40ce{/jobs/job/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.002+0530", "@message": "Started o.s.j.s.ServletContextHandler@1888720c{/stages,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.002+0530", "@message": "Started o.s.j.s.ServletContextHandler@5d1a4951{/stages/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.004+0530", "@message": "Started o.s.j.s.ServletContextHandler@268f51e4{/stages/stage,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.006+0530", "@message": "Started o.s.j.s.ServletContextHandler@55c55f88{/stages/stage/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.008+0530", "@message": "Started o.s.j.s.ServletContextHandler@1c76cd29{/stages/pool,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.009+0530", "@message": "Started o.s.j.s.ServletContextHandler@40e34563{/stages/pool/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.010+0530", "@message": "Started o.s.j.s.ServletContextHandler@7fcc2e39{/storage,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.011+0530", "@message": "Started o.s.j.s.ServletContextHandler@31cf58f1{/storage/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.011+0530", "@message": "Started o.s.j.s.ServletContextHandler@37fcf6f8{/storage/rdd,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.013+0530", "@message": "Started o.s.j.s.ServletContextHandler@79628626{/storage/rdd/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.015+0530", "@message": "Started o.s.j.s.ServletContextHandler@7db2b6a5{/environment,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.017+0530", "@message": "Started o.s.j.s.ServletContextHandler@2857f72d{/environment/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.019+0530", "@message": "Started o.s.j.s.ServletContextHandler@23048381{/executors,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.021+0530", "@message": "Started o.s.j.s.ServletContextHandler@39c9d00f{/executors/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.021+0530", "@message": "Started o.s.j.s.ServletContextHandler@2d301f85{/executors/threadDump,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.023+0530", "@message": "Started o.s.j.s.ServletContextHandler@713604c2{/executors/threadDump/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.032+0530", "@message": "Started o.s.j.s.ServletContextHandler@a604d25{/static,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.035+0530", "@message": "Started o.s.j.s.ServletContextHandler@43ad8158{/,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.037+0530", "@message": "Started o.s.j.s.ServletContextHandler@722aa015{/api,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.040+0530", "@message": "Started o.s.j.s.ServletContextHandler@66fa2488{/jobs/job/kill,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.041+0530", "@message": "Started o.s.j.s.ServletContextHandler@58c58947{/stages/stage/kill,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.046+0530", "@message": "Started o.s.j.s.ServletContextHandler@62a4c76d{/metrics/json,null,AVAILABLE,@Spark}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.handler.ContextHandler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.191+0530", "@message": "ird_1214: Job started from main.py", "@fields": {"priority": "INFO", "logger_name": "main-logger", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.197+0530", "@message": "ird_1214: Log from helper function - this may appear in executor or driver depending on where it's called.", "@fields": {"priority": "INFO", "logger_name": "helper-logger", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.481+0530", "@message": "Starting job: foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:51.501+0530", "@message": "Got job 0 (foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42) with 12 output partitions", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.501+0530", "@message": "Final stage: ResultStage 0 (foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.501+0530", "@message": "Parents of final stage: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.501+0530", "@message": "Missing parents: List()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.501+0530", "@message": "Submitting ResultStage 0 (PythonRDD[1] at foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42), which has no missing parents", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.599+0530", "@message": "Block broadcast_0 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.698+0530", "@message": "Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.698+0530", "@message": "Added broadcast_0_piece0 in memory on IrshadAlam:61721 (size: 5.0 KiB, free: 434.4 MiB)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerInfo", "thread": "dispatcher-BlockManagerMaster"}}
{"@timestamp": "2025-05-01T18:19:51.698+0530", "@message": "Created broadcast 0 from broadcast at DAGScheduler.scala:1513", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.720+0530", "@message": "Submitting 12 missing tasks from ResultStage 0 (PythonRDD[1] at foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.725+0530", "@message": "Adding task set 0.0 with 12 tasks resource profile 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:51.771+0530", "@message": "Starting task 0.0 in stage 0.0 (TID 0) (IrshadAlam, executor driver, partition 0, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.784+0530", "@message": "Starting task 1.0 in stage 0.0 (TID 1) (IrshadAlam, executor driver, partition 1, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.786+0530", "@message": "Starting task 2.0 in stage 0.0 (TID 2) (IrshadAlam, executor driver, partition 2, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.788+0530", "@message": "Starting task 3.0 in stage 0.0 (TID 3) (IrshadAlam, executor driver, partition 3, PROCESS_LOCAL, 4460 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.788+0530", "@message": "Starting task 4.0 in stage 0.0 (TID 4) (IrshadAlam, executor driver, partition 4, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.789+0530", "@message": "Starting task 5.0 in stage 0.0 (TID 5) (IrshadAlam, executor driver, partition 5, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.790+0530", "@message": "Starting task 6.0 in stage 0.0 (TID 6) (IrshadAlam, executor driver, partition 6, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.790+0530", "@message": "Starting task 7.0 in stage 0.0 (TID 7) (IrshadAlam, executor driver, partition 7, PROCESS_LOCAL, 4460 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.790+0530", "@message": "Starting task 8.0 in stage 0.0 (TID 8) (IrshadAlam, executor driver, partition 8, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.792+0530", "@message": "Starting task 9.0 in stage 0.0 (TID 9) (IrshadAlam, executor driver, partition 9, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.792+0530", "@message": "Starting task 10.0 in stage 0.0 (TID 10) (IrshadAlam, executor driver, partition 10, PROCESS_LOCAL, 4433 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.794+0530", "@message": "Starting task 11.0 in stage 0.0 (TID 11) (IrshadAlam, executor driver, partition 11, PROCESS_LOCAL, 4460 bytes) taskResourceAssignments Map()", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "dispatcher-event-loop-10"}}
{"@timestamp": "2025-05-01T18:19:51.813+0530", "@message": "Running task 10.0 in stage 0.0 (TID 10)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 10.0 in stage 0.0 (TID 10)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 0.0 in stage 0.0 (TID 0)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 0.0 (TID 0)"}}
{"@timestamp": "2025-05-01T18:19:51.813+0530", "@message": "Running task 8.0 in stage 0.0 (TID 8)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 8.0 in stage 0.0 (TID 8)"}}
{"@timestamp": "2025-05-01T18:19:51.813+0530", "@message": "Running task 3.0 in stage 0.0 (TID 3)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 3.0 in stage 0.0 (TID 3)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 1.0 in stage 0.0 (TID 1)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 1.0 in stage 0.0 (TID 1)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 5.0 in stage 0.0 (TID 5)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 5.0 in stage 0.0 (TID 5)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 11.0 in stage 0.0 (TID 11)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 11.0 in stage 0.0 (TID 11)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 7.0 in stage 0.0 (TID 7)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 7.0 in stage 0.0 (TID 7)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 6.0 in stage 0.0 (TID 6)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 6.0 in stage 0.0 (TID 6)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 2.0 in stage 0.0 (TID 2)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 2.0 in stage 0.0 (TID 2)"}}
{"@timestamp": "2025-05-01T18:19:51.814+0530", "@message": "Running task 4.0 in stage 0.0 (TID 4)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 4.0 in stage 0.0 (TID 4)"}}
{"@timestamp": "2025-05-01T18:19:51.813+0530", "@message": "Running task 9.0 in stage 0.0 (TID 9)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 9.0 in stage 0.0 (TID 9)"}}
{"@timestamp": "2025-05-01T18:19:52.402+0530", "@message": "Times: total = 451, boot = 435, init = 16, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 9.0 in stage 0.0 (TID 9)"}}
{"@timestamp": "2025-05-01T18:19:52.794+0530", "@message": "Times: total = 839, boot = 837, init = 2, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 10.0 in stage 0.0 (TID 10)"}}
{"@timestamp": "2025-05-01T18:19:53.193+0530", "@message": "Times: total = 1242, boot = 1234, init = 8, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 5.0 in stage 0.0 (TID 5)"}}
{"@timestamp": "2025-05-01T18:19:53.600+0530", "@message": "Times: total = 1654, boot = 1636, init = 18, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 3.0 in stage 0.0 (TID 3)"}}
{"@timestamp": "2025-05-01T18:19:54.007+0530", "@message": "Times: total = 2062, boot = 2053, init = 9, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 11.0 in stage 0.0 (TID 11)"}}
{"@timestamp": "2025-05-01T18:19:54.410+0530", "@message": "Times: total = 2468, boot = 2456, init = 12, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 0.0 in stage 0.0 (TID 0)"}}
{"@timestamp": "2025-05-01T18:19:54.812+0530", "@message": "Times: total = 2864, boot = 2852, init = 12, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 8.0 in stage 0.0 (TID 8)"}}
{"@timestamp": "2025-05-01T18:19:55.193+0530", "@message": "Times: total = 3255, boot = 3240, init = 15, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 1.0 in stage 0.0 (TID 1)"}}
{"@timestamp": "2025-05-01T18:19:55.596+0530", "@message": "Times: total = 3645, boot = 3636, init = 9, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 2.0 in stage 0.0 (TID 2)"}}
{"@timestamp": "2025-05-01T18:19:55.989+0530", "@message": "Times: total = 4046, boot = 4019, init = 27, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 4.0 in stage 0.0 (TID 4)"}}
{"@timestamp": "2025-05-01T18:19:56.396+0530", "@message": "Times: total = 4450, boot = 4434, init = 16, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 7.0 in stage 0.0 (TID 7)"}}
{"@timestamp": "2025-05-01T18:19:56.802+0530", "@message": "Finished task 5.0 in stage 0.0 (TID 5). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 5.0 in stage 0.0 (TID 5)"}}
{"@timestamp": "2025-05-01T18:19:56.802+0530", "@message": "Finished task 9.0 in stage 0.0 (TID 9). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 9.0 in stage 0.0 (TID 9)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 11.0 in stage 0.0 (TID 11). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 11.0 in stage 0.0 (TID 11)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 3.0 in stage 0.0 (TID 3). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 3.0 in stage 0.0 (TID 3)"}}
{"@timestamp": "2025-05-01T18:19:56.802+0530", "@message": "Finished task 1.0 in stage 0.0 (TID 1). 1319 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 1.0 in stage 0.0 (TID 1)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 10.0 in stage 0.0 (TID 10). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 10.0 in stage 0.0 (TID 10)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Times: total = 4857, boot = 4835, init = 22, finish = 0", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonRunner", "thread": "Executor task launch worker for task 6.0 in stage 0.0 (TID 6)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 8.0 in stage 0.0 (TID 8). 1319 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 8.0 in stage 0.0 (TID 8)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 0.0 in stage 0.0 (TID 0). 1319 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 0.0 in stage 0.0 (TID 0)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 7.0 in stage 0.0 (TID 7). 1319 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 7.0 in stage 0.0 (TID 7)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 4.0 in stage 0.0 (TID 4). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 4.0 in stage 0.0 (TID 4)"}}
{"@timestamp": "2025-05-01T18:19:56.805+0530", "@message": "Finished task 2.0 in stage 0.0 (TID 2). 1319 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 2.0 in stage 0.0 (TID 2)"}}
{"@timestamp": "2025-05-01T18:19:56.806+0530", "@message": "Finished task 6.0 in stage 0.0 (TID 6). 1276 bytes result sent to driver", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.executor.Executor", "thread": "Executor task launch worker for task 6.0 in stage 0.0 (TID 6)"}}
{"@timestamp": "2025-05-01T18:19:56.820+0530", "@message": "Finished task 4.0 in stage 0.0 (TID 4) in 5030 ms on IrshadAlam (executor driver) (1/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:19:56.823+0530", "@message": "Finished task 5.0 in stage 0.0 (TID 5) in 5034 ms on IrshadAlam (executor driver) (2/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:19:56.824+0530", "@message": "Finished task 9.0 in stage 0.0 (TID 9) in 5032 ms on IrshadAlam (executor driver) (3/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-3"}}
{"@timestamp": "2025-05-01T18:19:56.825+0530", "@message": "Finished task 2.0 in stage 0.0 (TID 2) in 5040 ms on IrshadAlam (executor driver) (4/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:19:56.826+0530", "@message": "Finished task 6.0 in stage 0.0 (TID 6) in 5037 ms on IrshadAlam (executor driver) (5/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:19:56.827+0530", "@message": "Finished task 11.0 in stage 0.0 (TID 11) in 5033 ms on IrshadAlam (executor driver) (6/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-3"}}
{"@timestamp": "2025-05-01T18:19:56.828+0530", "@message": "Finished task 3.0 in stage 0.0 (TID 3) in 5041 ms on IrshadAlam (executor driver) (7/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:19:56.829+0530", "@message": "Finished task 10.0 in stage 0.0 (TID 10) in 5037 ms on IrshadAlam (executor driver) (8/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:19:56.830+0530", "@message": "Connected to AccumulatorServer at host: 127.0.0.1 port: 61722", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.api.python.PythonAccumulatorV2", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:56.830+0530", "@message": "Finished task 1.0 in stage 0.0 (TID 1) in 5046 ms on IrshadAlam (executor driver) (9/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-0"}}
{"@timestamp": "2025-05-01T18:19:56.831+0530", "@message": "Finished task 8.0 in stage 0.0 (TID 8) in 5041 ms on IrshadAlam (executor driver) (10/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-3"}}
{"@timestamp": "2025-05-01T18:19:56.833+0530", "@message": "Finished task 0.0 in stage 0.0 (TID 0) in 5071 ms on IrshadAlam (executor driver) (11/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-2"}}
{"@timestamp": "2025-05-01T18:19:56.834+0530", "@message": "Finished task 7.0 in stage 0.0 (TID 7) in 5044 ms on IrshadAlam (executor driver) (12/12)", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSetManager", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:19:56.834+0530", "@message": "Removed TaskSet 0.0, whose tasks have all completed, from pool ", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "task-result-getter-1"}}
{"@timestamp": "2025-05-01T18:19:56.846+0530", "@message": "ResultStage 0 (foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42) finished in 5.307 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:56.857+0530", "@message": "Job 0 is finished. Cancelling potential speculative or zombie tasks for this job", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:56.858+0530", "@message": "Killing all running tasks in stage 0: Stage finished", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.TaskSchedulerImpl", "thread": "dag-scheduler-event-loop"}}
{"@timestamp": "2025-05-01T18:19:56.862+0530", "@message": "Job 0 finished: foreach at C:\Users\erirs\projects\ird-projects\aws_projects\my_glue_job\main.py:42, took 5.379591 s", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.DAGScheduler", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:56.878+0530", "@message": "ird_1214: Job completed", "@fields": {"priority": "INFO", "logger_name": "main-logger", "thread": "Thread-4"}}
{"@timestamp": "2025-05-01T18:19:56.918+0530", "@message": "Invoking stop() from shutdown hook", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.928+0530", "@message": "Stopped Spark@1ea5ff72{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}", "@fields": {"priority": "INFO", "logger_name": "org.sparkproject.jetty.server.AbstractConnector", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.933+0530", "@message": "Stopped Spark web UI at http://IrshadAlam:4040", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.ui.SparkUI", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.944+0530", "@message": "MapOutputTrackerMasterEndpoint stopped!", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.MapOutputTrackerMasterEndpoint", "thread": "dispatcher-event-loop-3"}}
{"@timestamp": "2025-05-01T18:19:56.957+0530", "@message": "MemoryStore cleared", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.memory.MemoryStore", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.957+0530", "@message": "BlockManager stopped", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.964+0530", "@message": "BlockManagerMaster stopped", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.storage.BlockManagerMaster", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.968+0530", "@message": "OutputCommitCoordinator stopped!", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint", "thread": "dispatcher-event-loop-6"}}
{"@timestamp": "2025-05-01T18:19:56.980+0530", "@message": "Successfully stopped SparkContext", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.SparkContext", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.981+0530", "@message": "Shutdown hook called", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.982+0530", "@message": "Deleting directory C:\Users\erirs\AppData\Local\Temp\spark-0df655dd-1da4-4a4f-b3cb-f8035016495e", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.983+0530", "@message": "Deleting directory C:\Users\erirs\AppData\Local\Temp\spark-dff97f00-ba7e-46cc-b039-eca868e29aac", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
{"@timestamp": "2025-05-01T18:19:56.986+0530", "@message": "Deleting directory C:\Users\erirs\AppData\Local\Temp\spark-dff97f00-ba7e-46cc-b039-eca868e29aac\pyspark-05cf6ec7-8889-4a7f-be0f-19cc16941372", "@fields": {"priority": "INFO", "logger_name": "org.apache.spark.util.ShutdownHookManager", "thread": "shutdown-hook-0"}}
